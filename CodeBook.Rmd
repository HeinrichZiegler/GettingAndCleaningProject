---
title: "CodeBook"
author: "Heinrich Ziegler"
date: "10/22/2020"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## CodeBook: Peer-graded Assignment: Getting and Cleaning Data Course Project

In order to get and clean/tidy the requested data just run run_analysis.R

The script follows the 5-step criteria as stated in the assignment description.

However, before processing the data is needs first to be loaded of the internet and then unzipped.

### Downloading the data

downloading...

```{r downloading data}
  library(dplyr)

  destfile <- 'Coursera_DS3_Final.zip'
  
  if (!file.exists(destfile)){
    fileURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip'
    
    download.file(fileURL, destfile, method='curl')
    
  } 
```


### Unzipping data
The zipped file contains a folder "UCI HAR Dataset" folder.
If it already exists then don't unzip again

```{r unzipping data}
if (!file.exists("UCI HAR Dataset")) { 
  unzip(destfile) 
}
```


### loading and assigning content

Following variables are loaded with the data from the individual files extracted in the previous step

- activities: data.frame; 6 rows, 2 columns; Desc: List of activities represented by Id used in other files as reference

- features: data.frame; 561 rows, 2 columns; list of action processing functions accompanied by and id (n) 

- subject_train: data.frame; subject train data with 7352 rows and 1 column; id of 21 unique train subjects

- x_train: data.frame; 7352 rows and 561 columns; each column name matches the row values of feature file, thus representing functions

- y-train: data.frame; 7352 rows and 1 column; contains the matching activity codes for the x-train data

- subject_test: data.frame; subject test data with 2947 rows and 1 column; id of 9 unique test subjects

- x_test: data.frame; 2947 rows and 561 columns; corresponding test data each column name matches the row values of feature file, thus representing functions

- y-test: data.frame; 2947 rows and 1 column; contains the matching activity codes for the x-test data

```{r loading and assigning}

activities <- read.table("UCI HAR Dataset/activity_labels.txt", 
                        col.names = c("id", "activity"))
features <- read.table("UCI HAR Dataset/features.txt", 
                        col.names = c("n","functions"))
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt", 
                        col.names = "subject")
x_train <- read.table("UCI HAR Dataset/train/X_train.txt", 
                        col.names = features$functions)
y_train <- read.table("UCI HAR Dataset/train/y_train.txt", 
                        col.names = "id")
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt", 
                        col.names = "subject")
x_test <- read.table("UCI HAR Dataset/test/X_test.txt", 
                        col.names = features$functions)
y_test <- read.table("UCI HAR Dataset/test/y_test.txt", 
                        col.names = "id")

```

### Step 1: Merges the training and the test sets to create one data set

- xAll: 10299 rows, 561 columns after merging X values 

- yAll: 10299 rows, 1 column after merging Y values

- subjectAll: 10299 rows, 1 column after merging subject values

- compositeData: 10299 rows, 563 columns after column merging all three data.frames mentioned above

```{r merging data }
xAll <- rbind(x_train, x_test)
yAll <- rbind(y_train, y_test)

subjectAll <- rbind(subject_train, subject_test)

compositeData <- cbind(subjectAll, yAll, xAll)
```


### Step2: Extracts only the measurements on the mean and standard deviation for each measurement

- extractData: 10299 rows and 88 columns, after extracting

```{r extact mean and std data only}
extractedData <- select(compositeData, subject, id, contains("mean"), contains("std"))

```

### Step3: Uses descriptive activity names to name the activities in the data set

- First we change the codes into the actual activities

```{r change code to activities}
extractedData$id <- activities[extractedData$id,2]

```

### Step4: Appropriately labels the data set with descriptive variable names.

- then we clean out abbreviations like acc to Accelerometer and others

- then turning all names into camel case, which makes it more readable to IT personnel

```{r modify/clean names}
# Appropriately labels the data set with descriptive variable names.
# removing dots(.) and Transform everything into camel case as used
# as standards in many programming languages

colnames(extractedData)<-gsub("Acc", "Accelerometer", colnames(extractedData))
colnames(extractedData)<-gsub("^t", "Time", colnames(extractedData))
colnames(extractedData)<-gsub("\\.mean", "Mean", colnames(extractedData))
colnames(extractedData)<-gsub("Freq", "Frequency", colnames(extractedData))
colnames(extractedData)<-gsub("^f", "Frequency", colnames(extractedData))
colnames(extractedData)<-gsub("Gyro", "Gyroscope", colnames(extractedData))
colnames(extractedData)<-gsub("BodyBody", "Body", colnames(extractedData))
colnames(extractedData)<-gsub("Mag", "Magnitude", colnames(extractedData))
colnames(extractedData)<-gsub("\\.gravity", "Gravity", colnames(extractedData))
colnames(extractedData)<-gsub("Acc", "Accelerometer", colnames(extractedData))
colnames(extractedData)<-gsub("^t", "Time", colnames(extractedData))
colnames(extractedData)<-gsub("\\.mean", "Mean", colnames(extractedData))
colnames(extractedData)<-gsub("Freq", "Frequency", colnames(extractedData))
colnames(extractedData)<-gsub("^f", "Frequency", colnames(extractedData))
colnames(extractedData)<-gsub("Gyro", "Gyroscope", colnames(extractedData))
colnames(extractedData)<-gsub("BodyBody", "Body", colnames(extractedData))
colnames(extractedData)<-gsub("Mag", "Magnitude", colnames(extractedData))
colnames(extractedData)<-gsub("^anglet", "AngleTime", colnames(extractedData))
colnames(extractedData)<-gsub("^angle", "Angle", colnames(extractedData))
colnames(extractedData)<-gsub("std", "StandardDeviation", colnames(extractedData))

# now remove the remaining dots
colnames(extractedData)<-gsub("\\.", "", colnames(extractedData))

# adapt the first two columns to match
colnames(extractedData)[1] = "Subject"
colnames(extractedData)[2] = "Activity"
# now remove the remaining dots
colnames(extractedData)<-gsub("\\.", "", colnames(extractedData))

```

### Step 5: From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.

```{r tidying,summarizing adn storing data}
write.table(extractedData, "TidyExtractedData.txt", row.name=FALSE)
SummaryData <- extractedData %>% group_by(Subject, Activity) %>% summarise_all(list(mean))
write.table(SummaryData, "SummaryData.txt", row.name=FALSE)
```

SummaryData contains the result data